{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82a8f4dd",
   "metadata": {},
   "source": [
    "# arXiv Paper Curator -  Infrastructure Setup\n",
    "\n",
    "Build a production-grade RAG system using Docker, PostgreSQL, OpenSearch, FastAPI, Airflow, and Ollama.\n",
    "\n",
    "## Technology Stack\n",
    "| Component | Purpose | Port |\n",
    "|-----------|---------|------|\n",
    "| **FastAPI** | REST API | 8000 |\n",
    "| **PostgreSQL** | Paper metadata storage | 5432 |\n",
    "| **OpenSearch** | Hybrid search engine | 9200/5601 |\n",
    "| **Apache Airflow** | Workflow automation | 8080 |\n",
    "| **Ollama** | Local LLM inference | 11434 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c012f298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.12.0\n",
      "Environment: c:\\Users\\shubh\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\n",
      "✓ Python version compatible\n"
     ]
    }
   ],
   "source": [
    "# Environment Check\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "python_version = sys.version_info\n",
    "print(f\"Python Version: {python_version.major}.{python_version.minor}.{python_version.micro}\")\n",
    "print(f\"Environment: {sys.executable}\")\n",
    "\n",
    "if python_version >= (3, 12):\n",
    "    print(\"✓ Python version compatible\")\n",
    "else:\n",
    "    print(\"✗ Need Python 3.12+\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07425f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: c:\\Users\\shubh\\OneDrive\\Documents\\RAG_Research_Paper_Assistant\\notebooks\\setup\n",
      "Directory Name: setup\n",
      "Parent Directory Name: notebooks\n",
      "Grandparent Directory Name: RAG_Research_Paper_Assistant\n",
      "✓ Project root: c:\\Users\\shubh\\OneDrive\\Documents\\RAG_Research_Paper_Assistant\n"
     ]
    }
   ],
   "source": [
    "# Find Project Root\n",
    "current_dir = Path.cwd()\n",
    "print(f\"Current Directory: {current_dir}\")\n",
    "print(f\"Directory Name: {current_dir.name}\")\n",
    "print(f\"Parent Directory Name: {current_dir.parent.name}\")\n",
    "print(f\"Grandparent Directory Name: {current_dir.parent.parent.name}\")\n",
    "\n",
    "if current_dir.name == \"setup\" and current_dir.parent.name == \"notebooks\":\n",
    "    project_root = current_dir.parent.parent\n",
    "elif (current_dir / \"compose.yml\").exists():\n",
    "    project_root = current_dir\n",
    "else:\n",
    "    project_root = None\n",
    "\n",
    "if project_root and (project_root / \"compose.yml\").exists():\n",
    "    print(f\"✓ Project root: {project_root}\")\n",
    "else:\n",
    "    print(\"✗ Missing compose.yml - check directory\")\n",
    "    exit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a73c94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Docker: Docker version 29.1.3, build f52814d\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check Docker\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    result = subprocess.run([\"docker\", \"--version\"], capture_output=True, text=True, timeout=5)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"✓ Docker: {result.stdout}\")\n",
    "    else:\n",
    "        print(\"✗ Docker: Not working\")\n",
    "        exit()\n",
    "except:\n",
    "    print(\"✗ Docker: Not found\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a90bf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Docker Compose: v5.0.1\n"
     ]
    }
   ],
   "source": [
    "# Check Docker Compose\n",
    "try:\n",
    "    result = subprocess.run([\"docker\", \"compose\", \"version\"], capture_output=True, text=True, timeout=5)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"✓ Docker Compose: {result.stdout.split()[3]}\")\n",
    "    else:\n",
    "        print(\"✗ Docker Compose: Not working\")\n",
    "        exit()\n",
    "except:\n",
    "    print(\"✗ Docker Compose: Not found\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d9edd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ UV: uv 0.9.28 (0e1351e40 2026-01-29)\n",
      "\n",
      "✓ All required software ready!\n"
     ]
    }
   ],
   "source": [
    "# Check UV Package Manager\n",
    "try:\n",
    "    result = subprocess.run([\"uv\", \"--version\"], capture_output=True, text=True, timeout=5)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"✓ UV: {result.stdout.strip()}\")\n",
    "        print(\"\\n✓ All required software ready!\")\n",
    "    else:\n",
    "        print(\"✗ UV: Not working\")\n",
    "        exit()\n",
    "except:\n",
    "    print(\"✗ UV: Not found\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bad9971",
   "metadata": {},
   "source": [
    "## Start Services\n",
    "\n",
    "**Command to run (in terminal):**\n",
    "```bash\n",
    "cd [project-root]\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "**What this does:** Downloads images (first time) and starts all services in background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e35d790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Docker is running\n"
     ]
    }
   ],
   "source": [
    "# Check Docker Running\n",
    "try:\n",
    "    result = subprocess.run([\"docker\", \"info\"], capture_output=True, timeout=5)\n",
    "    if result.returncode == 0:\n",
    "        print(\"✓ Docker is running\")\n",
    "    else:\n",
    "        print(\"✗ Docker not running - start Docker Desktop\")\n",
    "        exit()\n",
    "except:\n",
    "    print(\"✗ Docker daemon not accessible\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33c850ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current containers:\n"
     ]
    }
   ],
   "source": [
    "# Check Current Containers - Fixed encoding\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"docker\", \"compose\", \"ps\", \"--format\", \"json\"],\n",
    "        cwd=str(project_root),\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        encoding='utf-8',  # Force UTF-8 encoding\n",
    "        errors='ignore',   # Ignore problematic characters\n",
    "        timeout=10\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0 and result.stdout.strip():\n",
    "        print(\"Current containers:\")\n",
    "        for line in result.stdout.strip().split('\\n'):\n",
    "            if line.strip():\n",
    "                try:\n",
    "                    container = json.loads(line)\n",
    "                    service = container.get('Service', 'unknown')\n",
    "                    state = container.get('State', 'unknown')\n",
    "                    print(f\"  • {service}: {state}\")\n",
    "                except:\n",
    "                    pass\n",
    "    else:\n",
    "        print(\"No containers running\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(\"Could not check containers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cc18ea",
   "metadata": {},
   "source": [
    "## Service Health Verification\n",
    "\n",
    "All services start automatically. Check their health status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8429935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SERVICE STATUS\n",
      "======================================================================\n",
      "Service              State           Status          Notes\n",
      "----------------------------------------------------------------------\n",
      "⚠ api                running        unhealthy      Starting up...\n",
      "✓ clickhouse         running        healthy        Ready\n",
      "✓ opensearch-dashboards running        healthy        Ready\n",
      "✓ langfuse-minio     running        healthy        Ready\n",
      "✓ langfuse-postgres  running        healthy        Ready\n",
      "✓ langfuse-redis     running        healthy        Ready\n",
      "⚠ langfuse-web       running        unhealthy      Starting up...\n",
      "? langfuse-worker    running                       Status: running\n",
      "✓ ollama             running        healthy        Ready\n",
      "✓ opensearch         running        healthy        Ready\n",
      "✓ postgres           running        healthy        Ready\n",
      "✓ redis              running        healthy        Ready\n",
      "\n",
      "MISSING SERVICES:\n",
      "----------------------------------------------------------------------\n",
      "⚠ airflow            not running    (Optional)     Workflow automation (optional - may be off)\n",
      "\n",
      "TROUBLESHOOTING:\n",
      "   docker compose logs api\n",
      "   docker compose logs langfuse-web\n"
     ]
    }
   ],
   "source": [
    "# Service Health Check\n",
    "import json\n",
    "\n",
    "EXPECTED_SERVICES = {\n",
    "    'api': 'FastAPI REST API server',\n",
    "    'postgres': 'PostgreSQL database',\n",
    "    'opensearch': 'OpenSearch search engine', \n",
    "    'opensearch-dashboards': 'OpenSearch web dashboard',\n",
    "    'ollama': 'Local LLM inference server',\n",
    "    'airflow': 'Workflow automation (optional - may be off)'\n",
    "}\n",
    "\n",
    "found_services = set()\n",
    "service_states = {}\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"docker\", \"compose\", \"ps\", \"--format\", \"json\"],\n",
    "        cwd=str(project_root),\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        encoding='utf-8',\n",
    "        errors='ignore',\n",
    "        timeout=15\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"SERVICE STATUS\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"{'Service':<20} {'State':<15} {'Status':<15} {'Notes'}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        if result.stdout and result.stdout.strip():\n",
    "            for line in result.stdout.strip().split('\\n'):\n",
    "                if line.strip():\n",
    "                    try:\n",
    "                        container = json.loads(line)\n",
    "                        service = container.get('Service', 'unknown')\n",
    "                        state = container.get('State', 'unknown')\n",
    "                        health = container.get('Health', 'no check')\n",
    "                        \n",
    "                        found_services.add(service)\n",
    "                        service_states[service] = {'state': state, 'health': health}\n",
    "                        \n",
    "                        if state == 'running' and health in ['healthy', 'no check']:\n",
    "                            indicator = \"✓\"\n",
    "                            notes = \"Ready\"\n",
    "                        elif state == 'running' and health == 'unhealthy':\n",
    "                            indicator = \"⚠\"\n",
    "                            notes = \"Starting up...\"\n",
    "                        elif state == 'exited':\n",
    "                            indicator = \"✗\"\n",
    "                            notes = \"Failed to start\"\n",
    "                        else:\n",
    "                            indicator = \"?\"\n",
    "                            notes = f\"Status: {state}\"\n",
    "                        \n",
    "                        print(f\"{indicator} {service:<18} {state:<14} {health:<14} {notes}\")\n",
    "                        \n",
    "                    except json.JSONDecodeError:\n",
    "                        pass\n",
    "\n",
    "        # Check Missing Services\n",
    "        missing_services = set(EXPECTED_SERVICES.keys()) - found_services\n",
    "\n",
    "        if missing_services:\n",
    "            print(\"\\nMISSING SERVICES:\")\n",
    "            print(\"-\" * 70)\n",
    "            for service in missing_services:\n",
    "                description = EXPECTED_SERVICES[service]\n",
    "                if service == 'airflow':\n",
    "                    print(f\"⚠ {service:<18} not running    {'(Optional)':<14} {description}\")\n",
    "                else:\n",
    "                    print(f\"✗ {service:<18} not running    {'Required':<14} {description}\")\n",
    "\n",
    "        failed_services = [s for s, info in service_states.items() \n",
    "                          if info['state'] in ['exited', 'restarting'] or info['health'] == 'unhealthy']\n",
    "\n",
    "        if failed_services:\n",
    "            print(f\"\\nTROUBLESHOOTING:\")\n",
    "            for service in failed_services:\n",
    "                print(f\"   docker compose logs {service}\")\n",
    "        elif missing_services and 'airflow' not in missing_services:\n",
    "            print(f\"\\nACTION NEEDED:\")\n",
    "            print(\"Start missing services: docker compose up -d\")\n",
    "            \n",
    "    else:\n",
    "        print(\"Could not get service status\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error checking services: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ffc986e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MISSING SERVICES:\n",
      "----------------------------------------------------------------------\n",
      "⚠ airflow            not running    (Optional)     Workflow automation (optional - may be off)\n",
      "\n",
      "TROUBLESHOOTING:\n",
      "   docker compose logs api\n",
      "   docker compose logs langfuse-web\n"
     ]
    }
   ],
   "source": [
    "# Check Missing Services\n",
    "missing_services = set(EXPECTED_SERVICES.keys()) - found_services\n",
    "\n",
    "if missing_services:\n",
    "    print(\"\\nMISSING SERVICES:\")\n",
    "    print(\"-\" * 70)\n",
    "    for service in missing_services:\n",
    "        description = EXPECTED_SERVICES[service]\n",
    "        if service == 'airflow':\n",
    "            print(f\"⚠ {service:<18} not running    {'(Optional)':<14} {description}\")\n",
    "        else:\n",
    "            print(f\"✗ {service:<18} not running    {'Required':<14} {description}\")\n",
    "\n",
    "failed_services = [s for s, info in service_states.items() \n",
    "                  if info['state'] in ['exited', 'restarting'] or info['health'] == 'unhealthy']\n",
    "\n",
    "if failed_services:\n",
    "    print(f\"\\nTROUBLESHOOTING:\")\n",
    "    for service in failed_services:\n",
    "        print(f\"   docker compose logs {service}\")\n",
    "elif missing_services and 'airflow' not in missing_services:\n",
    "    print(f\"\\nACTION NEEDED:\")\n",
    "    print(\"Start missing services: docker compose up -d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d9c2e",
   "metadata": {},
   "source": [
    "### 1. FastAPI - REST API Service\n",
    "\n",
    "**Interactive Exploration:**\n",
    "\n",
    "You can explore and test the FastAPI service in several ways:\n",
    "- **API Documentation**: http://localhost:8000/docs (Interactive Swagger UI)\n",
    "- **Alternative Docs**: http://localhost:8000/redoc (ReDoc interface)\n",
    "- **Source Code**: Located in `src/routers/` directory\n",
    "\n",
    "Let's test the API endpoints and explore the documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d29e15c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ API not responding - wait 1-2 minutes\n"
     ]
    }
   ],
   "source": [
    "# Test FastAPI Health\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:8000/health\", timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(\"✓ FastAPI is responding\")\n",
    "        print(f\"Status: {data.get('status', 'unknown')}\")\n",
    "    else:\n",
    "        print(f\"⚠ API returned status: {response.status_code}\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"✗ API not responding - wait 1-2 minutes\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ API test error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "485a1df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Airflow password: admin123\n"
     ]
    }
   ],
   "source": [
    "# Get Airflow Password\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "password_file = project_root / \"airflow\" / \"simple_auth_manager_passwords.json.generated\"\n",
    "\n",
    "try:\n",
    "    if password_file.exists():\n",
    "        with open(password_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            password = data.get(\"admin\")\n",
    "        print(f\"✓ Airflow password: {password}\")\n",
    "    else:\n",
    "        print(f\"⚠ Password file not found\")\n",
    "        password = None\n",
    "except Exception as e:\n",
    "    print(f\"✗ Could not read password: {e}\")\n",
    "    password = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "584e53aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Airflow not responding - wait 2-3 minutes\n"
     ]
    }
   ],
   "source": [
    "# Test Airflow Health\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:8080/api/v2/monitor/health\", timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        print(\"✓ Airflow is healthy\")\n",
    "        \n",
    "        if password:\n",
    "            print(f\"\\nAirflow Login:\")\n",
    "            print(f\"URL: http://localhost:8080\")\n",
    "            print(f\"Username: admin\")\n",
    "            print(f\"Password: {password}\")\n",
    "    else:\n",
    "        print(f\"⚠ Airflow returned: {response.status_code}\")\n",
    "        \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"✗ Airflow not responding - wait 2-3 minutes\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Airflow test error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b6417",
   "metadata": {},
   "source": [
    "### 3. OpenSearch - Hybrid database\n",
    "\n",
    "**Interactive Exploration:**\n",
    "\n",
    "OpenSearch provides full-text search and analytics capabilities:\n",
    "- **API Endpoint**: http://localhost:9200 \n",
    "- **Dashboards UI**: http://localhost:5601 (Web interface)\n",
    "- **Source Code**: Located in `src/services/opensearch/` directory\n",
    "\n",
    "**Important for Students:** \n",
    "- ✅ Use http://localhost:5601 for web interface\n",
    "- ✅ Use Dev Tools in Dashboards for API queries\n",
    "\n",
    "Let's test OpenSearch and explore its capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc958ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OpenSearch Dashboards is accessible!\n",
      "✓ Web interface is ready for exploration\n",
      "\n",
      " Web Interface Access:\n",
      "========================================\n",
      "Main Dashboard: http://localhost:5601\n",
      "Dev Tools: http://localhost:5601/app/dev_tools\n",
      "========================================\n",
      "\n",
      " Student Learning Activities:\n",
      "1. Explore the Dashboard:\n",
      "   • Visit http://localhost:5601\n",
      "   • Navigate through the interface\n",
      "   • Check out the 'Discover' tab\n",
      "\n",
      "2. Use Dev Tools for API Queries:\n",
      "   • Go to Dev Tools\n",
      "   • Try: GET /_cluster/health\n",
      "   • Try: GET /_cat/indices?v\n",
      "   • Try: GET /_cluster/stats\n",
      "   • Check the learning material for more information\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Check OpenSearch Dashboards Web Interface\n",
    "# This is the proper way for students to interact with OpenSearch\n",
    "\n",
    "dashboards_url = \"http://localhost:5601\"\n",
    "\n",
    "try:\n",
    "    # Test if Dashboards is accessible\n",
    "    response = requests.get(f\"{dashboards_url}/api/status\", timeout=10, allow_redirects=True)\n",
    "    if response.status_code == 200:\n",
    "        print(\"✓ OpenSearch Dashboards is accessible!\")\n",
    "        print(\"✓ Web interface is ready for exploration\")\n",
    "        \n",
    "        print(\"\\n Web Interface Access:\")\n",
    "        print(\"=\" * 40)\n",
    "        print(f\"Main Dashboard: {dashboards_url}\")\n",
    "        print(f\"Dev Tools: {dashboards_url}/app/dev_tools\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        print(\"\\n Student Learning Activities:\")\n",
    "        print(\"1. Explore the Dashboard:\")\n",
    "        print(\"   • Visit http://localhost:5601\")\n",
    "        print(\"   • Navigate through the interface\")\n",
    "        print(\"   • Check out the 'Discover' tab\")\n",
    "        \n",
    "        print(\"\\n2. Use Dev Tools for API Queries:\")\n",
    "        print(\"   • Go to Dev Tools\")\n",
    "        print(\"   • Try: GET /_cluster/health\")\n",
    "        print(\"   • Try: GET /_cat/indices?v\")\n",
    "        print(\"   • Try: GET /_cluster/stats\")\n",
    "        print(\"   • Check the learning material for more information\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"⚠ Dashboards returned status: {response.status_code}\")\n",
    "        print(\"Interface may still be starting up\")\n",
    "        \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"✗ OpenSearch Dashboards not accessible yet\")\n",
    "    print(\"Wait 2-3 minutes for full startup\")\n",
    "    \n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"⚠ Dashboards request timed out\")\n",
    "    print(\"This is normal during startup - try again in a few minutes\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error accessing Dashboards: {e}\")\n",
    "    print(\"Check container status: docker compose ps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca061b3",
   "metadata": {},
   "source": [
    "### 4. Ollama - Local LLM Inference Engine\n",
    "\n",
    "**Interactive Exploration:**\n",
    "\n",
    "Ollama runs large language models locally on your machine:\n",
    "- **API Endpoint**: http://localhost:11434\n",
    "- **Command Line**: Available inside the container\n",
    "- **Privacy**: All AI processing happens locally (no external APIs)\n",
    "\n",
    "Let's test Ollama and see what models are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "254627ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ollama is running!\n",
      "Available models: 1\n",
      "\n",
      "Installed Models:\n",
      "  • llama3.2:1b (1.2 GB)\n",
      "\n",
      "  Try This Later (Week 4):\n",
      "1. docker exec -it rag-ollama ollama pull llama3.2\n",
      "2. docker exec -it rag-ollama ollama list\n",
      "3. docker exec -it rag-ollama ollama run llama3.2\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Check Ollama Service Status\n",
    "# Let's see if Ollama is running and what models are available\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "ollama_url = \"http://localhost:11434/api/tags\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(ollama_url, timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        models_data = response.json()\n",
    "        models = models_data.get('models', [])\n",
    "        \n",
    "        print(\"✓ Ollama is running!\")\n",
    "        print(f\"Available models: {len(models)}\")\n",
    "        \n",
    "        if models:\n",
    "            print(\"\\nInstalled Models:\")\n",
    "            for model in models:\n",
    "                name = model.get('name', 'unknown')\n",
    "                size = model.get('size', 0)\n",
    "                size_gb = round(size / (1024**3), 1)\n",
    "                print(f\"  • {name} ({size_gb} GB)\")\n",
    "        else:\n",
    "            print(\"\\n  No models installed yet\")\n",
    "            print(\"   This is normal - models are large files (3-7 GB each)\")\n",
    "            print(\"   In Week 4, we'll install a model like llama3.2\")\n",
    "            \n",
    "        print(\"\\n  Try This Later (Week 4):\")\n",
    "        print(\"1. docker exec -it rag-ollama ollama pull llama3.2\")\n",
    "        print(\"2. docker exec -it rag-ollama ollama list\")\n",
    "        print(\"3. docker exec -it rag-ollama ollama run llama3.2\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"⚠ Ollama returned status: {response.status_code}\")\n",
    "        \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"✗ Ollama is not responding yet\")\n",
    "    print(\"Ollama service might still be starting\")\n",
    "    \n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"✗ Ollama request timed out\")\n",
    "    print(\"Service might still be initializing\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Unexpected error testing Ollama: {e}\")\n",
    "    print(\"Try again in a few minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab211c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ollama API is healthy!\n",
      "Version: 0.11.2\n",
      "\n",
      "  What is Ollama?\n",
      "• Runs AI models completely on your local machine\n",
      "• No data sent to external services (privacy-first)\n",
      "• No API fees or rate limits\n",
      "• Supports models like Llama, Mistral, Phi, etc.\n",
      "\n",
      "  Coming in Week 4:\n",
      "• Install and run a local language model\n",
      "• Generate answers to research questions\n",
      "• Summarize academic papers\n",
      "• All processing stays on your computer!\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Check Ollama Version and Health\n",
    "# Let's verify Ollama is properly configured\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "ollama_version_url = \"http://localhost:11434/api/version\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(ollama_version_url, timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        version_data = response.json()\n",
    "        version = version_data.get('version', 'unknown')\n",
    "        \n",
    "        print(\"✓ Ollama API is healthy!\")\n",
    "        print(f\"Version: {version}\")\n",
    "        \n",
    "        print(\"\\n  What is Ollama?\")\n",
    "        print(\"• Runs AI models completely on your local machine\")\n",
    "        print(\"• No data sent to external services (privacy-first)\")\n",
    "        print(\"• No API fees or rate limits\")\n",
    "        print(\"• Supports models like Llama, Mistral, Phi, etc.\")\n",
    "        \n",
    "        print(\"\\n  Coming in Week 4:\")\n",
    "        print(\"• Install and run a local language model\")\n",
    "        print(\"• Generate answers to research questions\")\n",
    "        print(\"• Summarize academic papers\")\n",
    "        print(\"• All processing stays on your computer!\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"⚠ Ollama version check returned: {response.status_code}\")\n",
    "        \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"✗ Could not check Ollama version\")\n",
    "    print(\"Service might still be starting up\")\n",
    "    \n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"✗ Ollama request timed out\")\n",
    "    print(\"Service might still be initializing\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Unexpected error checking version: {e}\")\n",
    "    print(\"Try again in a few minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73e278b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOWNLOADING LLAMA 3.2:1B MODEL\n",
      "==================================================\n",
      "This is a small 1.3GB model - perfect for testing!\n",
      "Download will take 2-5 minutes depending on your internet speed...\n",
      "Llama 3.2:1b model downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# HANDS-ON: Pull and Test Llama 3.2 (Small Model)\n",
    "\n",
    "import requests\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "print(\"DOWNLOADING LLAMA 3.2:1B MODEL\")\n",
    "print(\"=\" * 50)\n",
    "print(\"This is a small 1.3GB model - perfect for testing!\")\n",
    "print(\"Download will take 2-5 minutes depending on your internet speed...\")\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"docker\", \"exec\", \"rag-ollama\", \"ollama\", \"pull\", \"llama3.2:1b\"],\n",
    "        cwd=str(project_root),\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=600,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"Llama 3.2:1b model downloaded successfully!\")\n",
    "    else:\n",
    "        print(f\"Download issue: {result.stderr}\")\n",
    "        \n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"Download timed out - this is normal for slow connections\")\n",
    "    print(\"The download continues in the background\")\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading model: {e}\")\n",
    "    print(\"Make sure Ollama container is running: docker compose ps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f59eab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing llama3.2:1b with prompt: 'What is machine learning in one sentence?'\n",
      "------------------------------------------------------------\n",
      "Generating response (this may take 10-30 seconds)...\n",
      "Response generated in 9.8 seconds\n",
      "\n",
      "RESPONSE:\n",
      "========================================\n",
      "Machine learning is a subset of artificial intelligence that enables computers to learn and improve from experience without being explicitly programmed, allowing them to make predictions, decisions, and take actions based on data and feedback.\n",
      "========================================\n",
      "\n",
      "Model: llama3.2:1b\n",
      "Generation time: 9779ms\n",
      "\n",
      "SUCCESS! Your local AI model is working!\n",
      "\n",
      "Try more prompts:\n",
      "• test_ollama_model(\"llama3.2:1b\", \"Explain neural networks simply\")\n",
      "• test_ollama_model(\"llama3.2:1b\", \"Write a Python function to sort a list\")\n"
     ]
    }
   ],
   "source": [
    "# Test Llama 3.2:1b API\n",
    "\n",
    "def test_ollama_model(model_name, prompt, max_wait_time=60):\n",
    "    \"\"\"Test an Ollama model with a prompt.\"\"\"\n",
    "    print(f\"Testing {model_name} with prompt: '{prompt}'\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(\"Generating response (this may take 10-30 seconds)...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = requests.post(url, json=data, timeout=max_wait_time)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            response_text = result.get('response', '').strip()\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Response generated in {elapsed_time:.1f} seconds\")\n",
    "            print(\"\\nRESPONSE:\")\n",
    "            print(\"=\" * 40)\n",
    "            print(response_text)\n",
    "            print(\"=\" * 40)\n",
    "            \n",
    "            if 'model' in result:\n",
    "                print(f\"\\nModel: {result['model']}\")\n",
    "            if 'total_duration' in result:\n",
    "                duration_ms = result['total_duration'] / 1000000\n",
    "                print(f\"Generation time: {duration_ms:.0f}ms\")\n",
    "                \n",
    "            return True\n",
    "            \n",
    "        else:\n",
    "            print(f\"API error: {response.status_code}\")\n",
    "            print(f\"Response: {response.text}\")\n",
    "            return False\n",
    "            \n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"Could not connect to Ollama API\")\n",
    "        print(\"Make sure Ollama is running: docker compose ps\")\n",
    "        return False\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\"Request timed out\")\n",
    "        print(\"Model might be loading for the first time (this is normal)\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return False\n",
    "\n",
    "test_prompt = \"What is machine learning in one sentence?\"\n",
    "success = test_ollama_model(\"llama3.2:1b\", test_prompt)\n",
    "\n",
    "if success:\n",
    "    print(\"\\nSUCCESS! Your local AI model is working!\")\n",
    "    print(\"\\nTry more prompts:\")\n",
    "    print('• test_ollama_model(\"llama3.2:1b\", \"Explain neural networks simply\")')\n",
    "    print('• test_ollama_model(\"llama3.2:1b\", \"Write a Python function to sort a list\")')\n",
    "else:\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Make sure model downloaded: docker exec rag-ollama ollama list\")\n",
    "    print(\"2. Check Ollama logs: docker compose logs ollama\")\n",
    "    print(\"3. Try again - first run takes longer to load model into memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f002d6a9",
   "metadata": {},
   "source": [
    "### 5. PostgreSQL - Database Storage\n",
    "\n",
    "**Interactive Exploration:**\n",
    "\n",
    "PostgreSQL stores all structured data for our application:\n",
    "- **Connection**: localhost:5432\n",
    "- **Database**: rag_db\n",
    "- **Username/Password**: rag_user / rag_password\n",
    "- **GUI Tool Recommendation**: DBeaver (free database client)\n",
    "\n",
    "Let's test the database connection and explore the schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afb164b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ PostgreSQL is accepting connections on port 5432!\n",
      "\n",
      "  Database Connection Details:\n",
      "• Host: localhost\n",
      "• Port: 5432\n",
      "• Database: rag_db\n",
      "• Username: rag_user\n",
      "• Password: rag_password\n",
      "\n",
      "  Recommended GUI Tools:\n",
      "• DBeaver (Free): https://dbeaver.io/download/\n",
      "• pgAdmin: https://www.pgadmin.org/download/\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Check PostgreSQL Connection (Basic)\n",
    "# Let's verify PostgreSQL is accepting connections\n",
    "\n",
    "def test_postgres_connection():\n",
    "    \"\"\"Test PostgreSQL connection using simple socket check.\"\"\"\n",
    "    import socket\n",
    "    \n",
    "    try:\n",
    "        # Test if PostgreSQL port is open\n",
    "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        sock.settimeout(3)\n",
    "        result = sock.connect_ex(('localhost', 5432))\n",
    "        sock.close()\n",
    "        \n",
    "        if result == 0:\n",
    "            print(\"✓ PostgreSQL is accepting connections on port 5432!\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"✗ PostgreSQL port is not accessible\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Could not test PostgreSQL: {e}\")\n",
    "        return False\n",
    "\n",
    "postgres_available = test_postgres_connection()\n",
    "\n",
    "if postgres_available:\n",
    "    print(\"\\n  Database Connection Details:\")\n",
    "    print(\"• Host: localhost\")\n",
    "    print(\"• Port: 5432\") \n",
    "    print(\"• Database: rag_db\")\n",
    "    print(\"• Username: rag_user\")\n",
    "    print(\"• Password: rag_password\")\n",
    "    \n",
    "    print(\"\\n  Recommended GUI Tools:\")\n",
    "    print(\"• DBeaver (Free): https://dbeaver.io/download/\")\n",
    "    print(\"• pgAdmin: https://www.pgadmin.org/download/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7e09bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Database connection failed: connection to server at \"localhost\" (::1), port 5432 failed: FATAL:  password authentication failed for user \"rag_user\"\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Test PostgreSQL Connection\n",
    "try:\n",
    "    import psycopg2\n",
    "    \n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        port=5432,\n",
    "        database=\"rag_db\", \n",
    "        user=\"rag_user\",\n",
    "        password=\"rag_password\"\n",
    "    )\n",
    "    \n",
    "    print(\"✓ PostgreSQL connected\")\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"⚠ psycopg2 not installed - basic connection only\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"✗ Database connection failed: {e}\")\n",
    "    exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
